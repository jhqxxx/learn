* DDPM:Denoising diffusion probabilistic models
    - 正向过程：给原始数据添加噪声，将有噪声图像经过模型产生噪声，loss计算原始噪声和产生的噪声的均方误差MSE，优化模型从有噪声的图像数据中产生真实噪声图像的能力，加噪的过程可以理解为多步加噪，但是加噪过程其实是一个多次添加基于高斯分布的噪声的过程，多次加噪可以参数重参化为只添加一次某一个分布的噪声。
    - 反向过程-去噪过程-生成过程：利用学到的噪声模型，逐步从纯噪声数据还原到生成图片 
    - 推理速度慢，生成图片过程中要采样T次，如果T=1000,那模型要经过1000次推理
    - 计算资源较大：Unet模型的U型结构，及上采样过程计算量大

* Latent Diffusion Models
    - 提出在潜在空间中进行扩散的改进方法，提升模型效率
    - 将扩散过程从高维的数据空间转移到低维的潜在空间中
        - 使用预训练的自动编码器将数据映射到潜在空间，
        - 然后在潜在空间进行扩散过程
        - 最后再通过解码器将潜在空间的数据还原到原始空间
        - 减少了计算开销，因为潜在空间的维度远低于原始数据空间 
        - LoRA将需要训练的模型矩阵降维到低秩矩阵计算再恢复到原始维度，和这个思路很像
    - 训练步骤
        - 自编码器-VAE：有两部分
            - 一个编码器：将图像转换为低维的潜在表示
            - 一个解码器：将潜在表示还原为图像
        - 潜在扩散模型-UNet：在低维潜在空间中进行扩散和去噪操作
        - 文本编码器：将文本输入映射为一系列嵌入向量

* DiffusionGAN

* Stable Diffusion
    - 训练时不会训练文本编码器，而是直接使用已经训练好的CLIP文本编码器
    - 自编码器的缩减因子为8，会将(3, 512, 512)的图像在潜在空间中变换为（3，64，64），空间压缩比为8*8=64
    - 模型同时接受一个潜在种子和文本提示作为输入
    - 使用潜在种子生成随机潜在图像表示，文本提示则使用CLIP的文本编码器转换为文本嵌入
    - UNet模型输入随机潜在图像和文本嵌入，输出噪声残差，通过调度算法计算出去噪后的潜在图像表示，逐步对随机潜在图像去噪
    - 去噪过程结束得到的潜在图像表示由变分自动编码器的解码器部分进行解码

* image2image:
    - 输入初始图像和文本提示，输出去噪后的图像
    - 初始图象被编码到潜在空间，并向其添加噪声，
    - UNet使用文本提示和加噪后的初始潜在图像预测噪声，逐步去噪
    - 解码器将去噪后的潜在图像解码

* Kandinsky：image2imge，输入image转成图像向量，更好的对齐文本向量和noise

* Inpainting: mask要保留的用黑色表示，要删除的用白色表示,mask blur将保留和删除区域更柔和

* video generation:

* ControlNet:

* 去噪调度算法：
    - DDPM
    - PNDM
    - DDIM
    - K-LMS

* UNet2DModel
    - 